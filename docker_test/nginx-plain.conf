events {
  worker_connections 1024;
}

error_log stderr;

http {
  resolver 127.0.0.11 ipv6=off;

  lua_package_path "/usr/local/openresty/lualib/?.lua;/usr/local/openresty/luajit/share/lua/5.1/?.lua;/lua/src/?.lua";
  lua_package_cpath "/usr/local/openresty/lualib/?.so;/usr/local/openresty/luajit/lib/lua/5.1/?.so;";

  upstream foo.com {
      server test-tls.com:443;
  }

  lua_shared_dict healthcheck 1m;
      init_worker_by_lua_block {
      local hc = require "healthcheck"

      local ok, err = hc.spawn_checker{
          shm = "healthcheck",  -- defined by "lua_shared_dict"
          upstream = "foo.com", -- defined by "upstream"
          type = "https",

          http_req = "GET /status HTTP/1.0\r\nHost: foo.com\r\n\r\n",
                  -- raw HTTP request for checking

          interval = 2000,  -- run the check cycle every 2 sec
          timeout = 1000,   -- 1 sec is the timeout for network operations
          fall = 3,  -- # of successive failures before turning a peer down
          rise = 2,  -- # of successive successes before turning a peer up
          valid_statuses = {200, 302},  -- a list valid HTTP status code
          concurrency = 10,  -- concurrency level for test requests
      }
      if not ok then
          ngx.log(ngx.ERR, "failed to spawn health checker: ", err)
          return
      end

      -- Just call hc.spawn_checker() for more times here if you have
      -- more upstream groups to monitor. One call for one upstream group.
      -- They can all share the same shm zone without conflicts but they
      -- need a bigger shm zone for obvious reasons.
  }


  server {
    listen 8080;

    location = /status {
      access_log off;
      default_type text/plain;
      content_by_lua_block {
        local hc = require "healthcheck"
          ngx.say("Nginx Worker PID: ", ngx.worker.pid())
          ngx.print(hc.status_page())
      }
    }

    location / {
      proxy_pass https://foo.com;
    }
  }
}

